{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 딥러닝 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.mlp1 = nn.Linear(input_size, hidden_size) # 입력 -> 히든\n",
    "        self.relu = nn.ReLU() # 활성함수\n",
    "        self.mlp2 = nn.Linear(hidden_size, num_classes)  # 히든 -> 출력\n",
    "        self.softmax = nn.Softmax(dim=1) # 최종 활성함수\n",
    "        \n",
    "    #  실제 돌아가는 함수 => 위에서 선언한 함수들을 작동\n",
    "    def forward(self, x):\n",
    "        out = self.mlp1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.mlp2(out)\n",
    "        out = self.softmax(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* cuda를 사용할 수 있으면 사용, 아니면 cpu환경으로"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNet(\n",
      "  (mlp1): Linear(in_features=784, out_features=100, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (mlp2): Linear(in_features=100, out_features=10, bias=True)\n",
      "  (softmax): Softmax(dim=1)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "input_size = 28*28*1 # MNIST 이미지 크기\n",
    "hidden_size = 100 # hyper parameter\n",
    "num_classes = 10 # 총 class 수 => 10개의 이미지 사용\n",
    "\n",
    "model = NeuralNet(input_size, hidden_size, num_classes).to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data: torch.Size([1, 784])\n",
      "----------------------------------------\n",
      "pred: tensor([[0.0959, 0.1064, 0.1097, 0.0860, 0.1225, 0.0702, 0.0962, 0.1140, 0.1001,\n",
      "         0.0991]], grad_fn=<SoftmaxBackward0>)\n",
      "----------------------------------------\n",
      "y hat: tensor([4])\n"
     ]
    }
   ],
   "source": [
    "data = torch.rand(1, 28*28).to(device)\n",
    "print('data:',data.shape)\n",
    "print('-'*40)\n",
    "\n",
    "pred = model(data)\n",
    "print('pred:',pred)\n",
    "print('-'*40)\n",
    "\n",
    "y_hat = pred.argmax(1) # 가장 높은 확률\n",
    "print('y hat:',y_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nn.Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(3,28,28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_after_fc: torch.Size([3, 100])\n"
     ]
    }
   ],
   "source": [
    "fc_layer = nn.Linear(in_features=28*28, out_features=100) # in_features=28*28 : 쭉 펴서 데이터를 넣어 적용 \n",
    "x_after_fc = fc_layer(x.reshape(-1,28*28))\n",
    "print('x_after_fc:',x_after_fc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 784])\n",
      "x_after_fc: torch.Size([3, 100])\n"
     ]
    }
   ],
   "source": [
    "# nn.Flatten : x.reshape(-1,28*28)과 같은 역할\n",
    "# 28x28 사이즈의 이미지를 784 픽셀 값을 갖는 배열로 변환\n",
    "\n",
    "flatten = nn.Flatten()\n",
    "flat_x = flatten(x)\n",
    "print(flat_x.shape)\n",
    "\n",
    "fc_layer = nn.Linear(in_features=28*28, out_features=100)\n",
    "x_after_fc = fc_layer(flat_x)\n",
    "print('x_after_fc:',x_after_fc.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nn.ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(3,28,28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-2.2632, -1.1601, -1.5708, -0.7098,  1.1240,  0.5832, -0.4920,  0.7810,\n",
       "        -1.0638,  0.0208,  0.2019, -0.5706,  1.8864,  0.7079,  0.4409, -0.6911,\n",
       "        -1.3627,  0.4620,  0.4089, -0.6376, -1.2141, -1.4225, -0.4005,  0.5099,\n",
       "        -1.4147, -0.9065, -1.8268,  1.4372])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ReLU : 음수들은 0으로, 양수는 양수 그대로"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before_relu : tensor([-2.2632, -1.1601, -1.5708, -0.7098,  1.1240,  0.5832, -0.4920,  0.7810,\n",
      "        -1.0638,  0.0208,  0.2019, -0.5706,  1.8864,  0.7079,  0.4409, -0.6911,\n",
      "        -1.3627,  0.4620,  0.4089, -0.6376, -1.2141, -1.4225, -0.4005,  0.5099,\n",
      "        -1.4147, -0.9065, -1.8268,  1.4372]) torch.Size([28])\n",
      "----------------------------------------------------------------------\n",
      "after_relu : tensor([0.0000, 0.0000, 0.0000, 0.0000, 1.1240, 0.5832, 0.0000, 0.7810, 0.0000,\n",
      "        0.0208, 0.2019, 0.0000, 1.8864, 0.7079, 0.4409, 0.0000, 0.0000, 0.4620,\n",
      "        0.4089, 0.0000, 0.0000, 0.0000, 0.0000, 0.5099, 0.0000, 0.0000, 0.0000,\n",
      "        1.4372]) torch.Size([28])\n"
     ]
    }
   ],
   "source": [
    "before_relu = x[0][0]\n",
    "print('before_relu :', before_relu, before_relu.shape)\n",
    "print('-'*70)\n",
    "\n",
    "relu = nn.ReLU()\n",
    "after_relu = relu(before_relu)\n",
    "print('after_relu :', after_relu, after_relu.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 뉴럴 네트워크의 output이라 생각(1,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.9890,  0.7847,  1.2137, -3.0404, -1.2543, -0.3276,  0.6636, -1.2009,\n",
       "         -0.3729, -0.2062]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(1,10)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Softmax(dim=1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax = nn.Softmax(dim=1)\n",
    "softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred: tensor([[0.0347, 0.2043, 0.3137, 0.0045, 0.0266, 0.0672, 0.1810, 0.0281, 0.0642,\n",
      "         0.0758]])\n",
      "sum of pred: tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "pred = softmax(x)\n",
    "print('pred:', pred)\n",
    "print('sum of pred:',pred.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nn.Sequential : 한번에 처리하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.mlp1 = nn.Linear(input_size, hidden_size) \n",
    "        self.relu = nn.ReLU()\n",
    "        self.mlp2 = nn.Linear(hidden_size, num_classes)  \n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "    def forward(self, x):\n",
    "        out = self.mlp1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.mlp2(out)\n",
    "        out = self.softmax(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNet(\n",
      "  (mlp1): Linear(in_features=784, out_features=100, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (mlp2): Linear(in_features=100, out_features=10, bias=True)\n",
      "  (softmax): Softmax(dim=1)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "input_size = 28*28*1 # MNIST 이미지 크기\n",
    "hidden_size = 100 # hyper parameter\n",
    "num_classes = 10 # 총 class 수\n",
    "\n",
    "model = NeuralNet(input_size, hidden_size, num_classes).to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nn.Sequential : 여러 모듈들을 묶어서 사용 가능\n",
    "\n",
    "class NeuralNet2(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        sequential = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, num_classes),\n",
    "            nn.Softmax(dim=1),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        out = self.sequential(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNet(\n",
      "  (mlp1): Linear(in_features=784, out_features=100, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (mlp2): Linear(in_features=100, out_features=10, bias=True)\n",
      "  (softmax): Softmax(dim=1)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "input_size = 28*28*1 # MNIST 이미지 크기\n",
    "hidden_size = 100 # hyper parameter\n",
    "num_classes = 10 # 총 class 수\n",
    "\n",
    "model = NeuralNet(input_size, hidden_size, num_classes).to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 손실 함수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Binary Cross Entropy Loss (nn.BCELoss())\n",
    "- `Binary Class (0/1)`에 적용\n",
    "- Loss 적용 전 `sigmoid`나 `softmax`를 취해줘야 함 => 확률 값으로 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(3)\n",
    "y = torch.tensor([0.,1.,0.]) # binary 이므로 target(y) 값은 0 또는 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: tensor([ 0.0467, -0.5376, -0.6343])\n",
      "y: tensor([0., 1., 0.])\n"
     ]
    }
   ],
   "source": [
    "print('x:',x)\n",
    "print('y:',y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "binary cross entropy loss value: tensor(0.7133)\n"
     ]
    }
   ],
   "source": [
    "# Binary Cross Entropy Loss\n",
    "bce_loss = nn.BCELoss()\n",
    "sigmoid = nn.Sigmoid()\n",
    "\n",
    "x_sigmoid = sigmoid(x) # Loss 적용 전 sigmoid/softmax로 확률값으로 변경\n",
    "print('binary cross entropy loss value:', bce_loss(x_sigmoid,y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Binary Cross Entropy With Logits Loss (nn.BCEWithLogitsLoss())\n",
    "- `Binary Class (0/1)`에 적용\n",
    "- Loss안에 `Sigmoid가 내장`되어있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "binary cross entropy loss value: tensor(0.7133)\n"
     ]
    }
   ],
   "source": [
    "# Binary Cross Entropy Loss\n",
    "bce_with_logits_loss = nn.BCEWithLogitsLoss() # => sigmoid 계산이 필요 없음\n",
    "\n",
    "print('binary cross entropy loss value:', bce_with_logits_loss(x,y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross Entropy Loss (nn.CrossEntropyLoss())\n",
    "- `Multi Class`에서 적용\n",
    "- Loss안에 `Softmax가 내장`되어 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(1,10)\n",
    "y = torch.tensor([1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: tensor([[ 1.0158, -2.0461,  1.5416, -0.4591, -0.9404, -0.1783, -0.9782,  1.9946,\n",
      "          1.0499, -1.0803]])\n",
      "y: tensor([1])\n"
     ]
    }
   ],
   "source": [
    "print('x:',x)\n",
    "print('y:',y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross_entropy loss value: tensor(5.0589)\n"
     ]
    }
   ],
   "source": [
    "# Cross Entropy Loss\n",
    "\n",
    "cross_entropy_loss = nn.CrossEntropyLoss()\n",
    "# Softmax와 Log를 한 후 Cross Entropy Loss\n",
    "\n",
    "print('cross_entropy loss value:', cross_entropy_loss(x,y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(1,10)\n",
    "y = torch.randn(1,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-1.0493,  0.7394,  1.2416, -2.7529, -1.1950, -0.4961, -0.0660,  0.3516,\n",
       "          -0.1618,  0.3677]]),\n",
       " tensor([[-2.1191, -1.3712,  0.0992, -0.6513, -0.4538, -0.4753, -0.4755,  0.4516,\n",
       "          -0.4128,  0.7341]]))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross_entropy loss value: tensor(1.4131)\n"
     ]
    }
   ],
   "source": [
    "mse_loss = nn.MSELoss()\n",
    "print('cross_entropy loss value:', mse_loss(x,y))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f2e2bce360819f88e39cac25630043f28fab3036cf9216375971b4d97393a103"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
