{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model, layers, optimizers, datasets\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Load**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------train----------------\n",
      "images: (60000, 28, 28) 0 255\n",
      "labels: (60000,)\n",
      "----------------test----------------\n",
      "images: (10000, 28, 28) 0 255\n",
      "labels: (10000,)\n"
     ]
    }
   ],
   "source": [
    "(images_train,labels_train), (images_test,labels_test) = datasets.mnist.load_data()\n",
    "print('----------------train----------------')\n",
    "print('images:',images_train.shape, images_train.min(), images_train.max())\n",
    "print('labels:',labels_train.shape)\n",
    "print('----------------test----------------')\n",
    "print('images:',images_test.shape, images_test.min(), images_test.max())\n",
    "print('labels:',labels_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Normalizing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [0,255] to [0,1]\n",
    "\n",
    "images_train = images_train/255.\n",
    "images_test = images_test/255."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    layers.Flatten(input_shape=(28, 28)),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/3\n",
      "60000/60000 [==============================] - 5s 85us/sample - loss: 0.2543 - accuracy: 0.9251\n",
      "Epoch 2/3\n",
      "60000/60000 [==============================] - 5s 80us/sample - loss: 0.1030 - accuracy: 0.9691\n",
      "Epoch 3/3\n",
      "60000/60000 [==============================] - 5s 83us/sample - loss: 0.0715 - accuracy: 0.9777\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7faf7e989c10>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(images_train, labels_train, epochs=3, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/1 - 1s - loss: 0.0457 - accuracy: 0.9720\n",
      "test accuracy: 0.972\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(images_test,  labels_test, verbose=2)\n",
    "\n",
    "print('test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet_dropout(Model):\n",
    "    def __init__(self, hidden_1, hidden_2, num_classes):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.fc1 = layers.Dense(hidden_1)\n",
    "        self.dropout1 = layers.Dropout()\n",
    "        self.fc2 = layers.Dense(hidden_2)\n",
    "        self.dropout2 = layers.Dropout()\n",
    "        self.out = layers.Dense(num_classes)\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = tf.nn.relu(x)\n",
    "        \n",
    "        x = self.fc2(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = tf.nn.relu(x)\n",
    "        \n",
    "        x = self.out(x)\n",
    "        x = tf.nn.softmax(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_1 = 128\n",
    "hidden_2 = 256\n",
    "num_classes = 10\n",
    "\n",
    "model_dropout = NeuralNet_dropout(hidden_1, hidden_2, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dropout.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dropout.fit(images_train, labels_train, epochs=3, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model_dropout.evaluate(images_test,  labels_test, verbose=2)\n",
    "\n",
    "print('test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet_bn(Model):\n",
    "    def __init__(self, hidden_1, hidden_2, num_classes):\n",
    "        super(NeuralNet_bn, self).__init__()\n",
    "\n",
    "        self.flatten = layers.Flatten(input_shape=(28,28))\n",
    "        self.fc1 = layers.Dense(hidden_1)\n",
    "        self.bn1 = layers.BatchNormalization()\n",
    "\n",
    "        self.fc2 = layers.Dense(hidden_2)\n",
    "        self.bn2 = layers.BatchNormalization()\n",
    "\n",
    "        self.out = layers.Dense(num_classes)\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = tf.nn.relu(x)\n",
    "\n",
    "        x = self.fc2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = tf.nn.relu(x)\n",
    "\n",
    "        x = self.out(x)\n",
    "        x = tf.nn.softmax(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_1 = 128\n",
    "hidden_2 = 256\n",
    "num_classes = 10\n",
    "\n",
    "model_bn = NeuralNet_bn(hidden_1, hidden_2, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_bn.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/3\n",
      "60000/60000 [==============================] - 8s 127us/sample - loss: 0.2063 - accuracy: 0.9381\n",
      "Epoch 2/3\n",
      "60000/60000 [==============================] - 7s 119us/sample - loss: 0.0911 - accuracy: 0.9721\n",
      "Epoch 3/3\n",
      "60000/60000 [==============================] - 7s 121us/sample - loss: 0.0653 - accuracy: 0.9790\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fb8fd409a90>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_bn.fit(images_train, labels_train, epochs=3, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/1 - 1s - loss: 0.0458 - accuracy: 0.9711\n",
      "test accuracy: 0.9711\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model_bn.evaluate(images_test,  labels_test, verbose=2)\n",
    "\n",
    "print('test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "minkyu",
   "language": "python",
   "name": "minkyu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
