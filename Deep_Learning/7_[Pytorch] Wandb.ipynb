{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wandb : Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Wandb : 데이터를 시각화하는 툴\n",
    "* tensorboard랑 비슷한 툴"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 0714fddca3d8c2ab50ab0e32cf0de1bdebc97316"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# MNIST 데이터셋 \n",
    "train_data = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transforms.ToTensor(),\n",
    ")\n",
    "\n",
    "test_data = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transforms.ToTensor(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting wandb\n",
      "  Downloading wandb-0.12.16-py2.py3-none-any.whl (1.8 MB)\n",
      "Collecting psutil>=5.0.0\n",
      "  Downloading psutil-5.9.0-cp38-cp38-win_amd64.whl (246 kB)\n",
      "Requirement already satisfied: protobuf>=3.12.0 in c:\\users\\jack0\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from wandb) (3.20.1)\n",
      "Collecting docker-pycreds>=0.4.0Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script shortuuid.exe is installed in 'c:\\Users\\jack0\\AppData\\Local\\Programs\\Python\\Python38\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The scripts wandb.exe and wb.exe are installed in 'c:\\Users\\jack0\\AppData\\Local\\Programs\\Python\\Python38\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "WARNING: You are using pip version 21.0.1; however, version 22.0.4 is available.\n",
      "You should consider upgrading via the 'c:\\Users\\jack0\\AppData\\Local\\Programs\\Python\\Python38\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
      "Collecting pathtools\n",
      "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
      "Collecting shortuuid>=0.5.0\n",
      "  Downloading shortuuid-1.0.8-py3-none-any.whl (9.5 kB)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in c:\\users\\jack0\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from wandb) (2.27.1)\n",
      "Collecting setproctitle\n",
      "  Downloading setproctitle-1.2.3-cp38-cp38-win_amd64.whl (10 kB)\n",
      "Collecting promise<3,>=2.0\n",
      "  Downloading promise-2.3.tar.gz (19 kB)\n",
      "Collecting sentry-sdk>=1.0.0\n",
      "  Downloading sentry_sdk-1.5.11-py2.py3-none-any.whl (144 kB)\n",
      "Requirement already satisfied: Click!=8.0.0,>=7.0 in c:\\users\\jack0\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from wandb) (7.1.2)\n",
      "Collecting GitPython>=1.0.0\n",
      "  Downloading GitPython-3.1.27-py3-none-any.whl (181 kB)\n",
      "Requirement already satisfied: setuptools in c:\\users\\jack0\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from wandb) (47.1.0)\n",
      "Requirement already satisfied: six>=1.13.0 in c:\\users\\jack0\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from wandb) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in c:\\users\\jack0\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from wandb) (2.8.2)\n",
      "Requirement already satisfied: PyYAML in c:\\users\\jack0\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from wandb) (6.0)\n",
      "Collecting gitdb<5,>=4.0.1\n",
      "  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n",
      "Collecting smmap<6,>=3.0.1\n",
      "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\jack0\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\jack0\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\jack0\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (1.26.9)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\jack0\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (2.0.12)\n",
      "Building wheels for collected packages: promise, pathtools\n",
      "  Building wheel for promise (setup.py): started\n",
      "  Building wheel for promise (setup.py): finished with status 'done'\n",
      "  Created wheel for promise: filename=promise-2.3-py3-none-any.whl size=21494 sha256=54e3f66f5eebc81486a60795234b6bfda19b43da38bc63267327f4f63c86bb90\n",
      "  Stored in directory: c:\\users\\jack0\\appdata\\local\\pip\\cache\\wheels\\54\\aa\\01\\724885182f93150035a2a91bce34a12877e8067a97baaf5dc8\n",
      "  Building wheel for pathtools (setup.py): started\n",
      "  Building wheel for pathtools (setup.py): finished with status 'done'\n",
      "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8785 sha256=2c9545da399eda043776d7262da4a052a2daaa6e08da4ecd4608b90dd12ebd53\n",
      "  Stored in directory: c:\\users\\jack0\\appdata\\local\\pip\\cache\\wheels\\4c\\8e\\7e\\72fbc243e1aeecae64a96875432e70d4e92f3d2d18123be004\n",
      "Successfully built promise pathtools\n",
      "Installing collected packages: smmap, gitdb, shortuuid, setproctitle, sentry-sdk, psutil, promise, pathtools, GitPython, docker-pycreds, wandb\n",
      "Successfully installed GitPython-3.1.27 docker-pycreds-0.4.0 gitdb-4.0.9 pathtools-0.1.2 promise-2.3 psutil-5.9.0 sentry-sdk-1.5.11 setproctitle-1.2.3 shortuuid-1.0.8 smmap-5.0.0 wandb-0.12.16\n"
     ]
    }
   ],
   "source": [
    "# pip install wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "wandb: You can find your API key in your browser here: https://wandb.ai/authorize\n",
      "wandb: Appending key for api.wandb.ai to your netrc file: C:\\Users\\jack0/.netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = dict(\n",
    "    total_epochs=3,\n",
    "    batch_size=128,\n",
    "    learning_rate=0.005,\n",
    "    num_classes=10,\n",
    "    hidden_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Currently logged in as: jack04215. Use `wandb login --relogin` to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.16"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\jack0\\OneDrive\\바탕 화면\\Python_ML\\Deep_Learning\\wandb\\run-20220507_154023-14w6cfvj</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/jack04215/fast_campus_deep_learning%28Pytorch%29/runs/14w6cfvj\" target=\"_blank\">trim-dawn-1</a></strong> to <a href=\"https://wandb.ai/jack04215/fast_campus_deep_learning%28Pytorch%29\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.init(project='fast_campus_deep_learning(Pytorch)') # 프로젝트 이름\n",
    "wandb.config.update(args) # 선언한 arg로 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loader\n",
    "train_loader = DataLoader(train_data, batch_size=args['batch_size'], shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=args['batch_size'], shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(Model, self).__init__()\n",
    "        # input size와 output size 모두 넣어주어야 함\n",
    "        # tensorflow에는 output demension만 넣음\n",
    "        self.mlp1 = nn.Linear(input_size, hidden_size) # input size와 output size\n",
    "        self.relu = nn.ReLU()\n",
    "        self.mlp2 = nn.Linear(hidden_size, num_classes)  \n",
    "    # tensorflow : call / pytorch : forward    \n",
    "    def forward(self, x): \n",
    "        out = self.mlp1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.mlp2(out)\n",
    "        \n",
    "        return out\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = Model(input_size=28*28*1, hidden_size=args['hidden_size'], num_classes=args['num_classes']).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CELoss = nn.CrossEntropyLoss()\n",
    "adam_optimizer = torch.optim.Adam(model.parameters(), lr=args['learning_rate']) # 최적화 알고리즘 class 선언\n",
    "wandb.watch(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'total_epochs': 3,\n",
       " 'batch_size': 128,\n",
       " 'learning_rate': 0.005,\n",
       " 'num_classes': 10,\n",
       " 'hidden_size': 100}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* optimizer.zero_grad() : 역전파 단계를 실행하기 전에 변화도(gradient)를 0으로 만듭니다\n",
    "* loss.backward() : backward로 미분하여 손실함수에 끼친 영향력(변화량)을 구하기 => 모델의 학습 가능한 모든 매개변수에 대해 손실의 변화도를 계산\n",
    "* ooptimizer.step() : 손실함수를 최적화하도록 파라미터를 업데이트하는 과정 => 매개변수가 갱신"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(args):\n",
    "    for epoch in range(args['total_epochs']):\n",
    "        for i, (images, labels) in enumerate(train_loader):\n",
    "            images_flatten = images.reshape(-1, 28*28).to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            outputs = model(images_flatten)\n",
    "            ce_loss = CELoss(outputs, labels)\n",
    "            \n",
    "            adam_optimizer.zero_grad() # zero_grad()로 .grad 값들을 0으로 초기화시킨 후 학습을 진행\n",
    "            ce_loss.backward() # 각 파라미터들의 .grad 값에 변화도가 저장\n",
    "            adam_optimizer.step() # 작동\n",
    "            \n",
    "            # 10번마다 한번씩 epoch, ce_loss 출력\n",
    "            if (i+1)%10 == 0:\n",
    "                log_dict = {'Current Epoch':epoch, 'CE Loss': ce_loss}\n",
    "                wandb.log(log_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model():\n",
    "\n",
    "    with torch.no_grad(): # back propagation 없음\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for i, (images, labels) in enumerate(test_loader):\n",
    "            print('i:',i)\n",
    "            images_flatten = images.reshape(-1, 28*28*1).to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(images_flatten)\n",
    "            _ , predicted = torch.max(outputs.data, 1) # 최대값 추출\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "            log_dict={\"test accuracy\":correct/total}\n",
    "            wandb.log(log_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* https://wandb.ai/home 들어가서 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i: 0\n",
      "i: 1\n",
      "i: 2\n",
      "i: 3\n",
      "i: 4\n",
      "i: 5\n",
      "i: 6\n",
      "i: 7\n",
      "i: 8\n",
      "i: 9\n",
      "i: 10\n",
      "i: 11\n",
      "i: 12\n",
      "i: 13\n",
      "i: 14\n",
      "i: 15\n",
      "i: 16\n",
      "i: 17\n",
      "i: 18\n",
      "i: 19\n",
      "i: 20\n",
      "i: 21\n",
      "i: 22\n",
      "i: 23\n",
      "i: 24\n",
      "i: 25\n",
      "i: 26\n",
      "i: 27\n",
      "i: 28\n",
      "i: 29\n",
      "i: 30\n",
      "i: 31\n",
      "i: 32\n",
      "i: 33\n",
      "i: 34\n",
      "i: 35\n",
      "i: 36\n",
      "i: 37\n",
      "i: 38\n",
      "i: 39\n",
      "i: 40\n",
      "i: 41\n",
      "i: 42\n",
      "i: 43\n",
      "i: 44\n",
      "i: 45\n",
      "i: 46\n",
      "i: 47\n",
      "i: 48\n",
      "i: 49\n",
      "i: 50\n",
      "i: 51\n",
      "i: 52\n",
      "i: 53\n",
      "i: 54\n",
      "i: 55\n",
      "i: 56\n",
      "i: 57\n",
      "i: 58\n",
      "i: 59\n",
      "i: 60\n",
      "i: 61\n",
      "i: 62\n",
      "i: 63\n",
      "i: 64\n",
      "i: 65\n",
      "i: 66\n",
      "i: 67\n",
      "i: 68\n",
      "i: 69\n",
      "i: 70\n",
      "i: 71\n",
      "i: 72\n",
      "i: 73\n",
      "i: 74\n",
      "i: 75\n",
      "i: 76\n",
      "i: 77\n",
      "i: 78\n"
     ]
    }
   ],
   "source": [
    "test_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model():\n",
    "    # 학습이 끝난 후 모델 성능 테스트\n",
    "    # test에서는 back propagation 작업을 하지 않으므로 gradient를 계산하지 않도록 함 - 메모리의 효율성을 위해\n",
    "    \n",
    "    images_ex = []\n",
    "    with torch.no_grad(): # gradient 계산하지 않도록 하는 코드\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for i, (images, labels) in enumerate(test_loader):\n",
    "            images_flatten = images.reshape(-1, 28*28).to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images_flatten)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "            if (i+1)%10 == 0: # 10번 iteration을 돌 때 마다\n",
    "                images_ex.append(wandb.Image(\n",
    "                    images[0], caption=\"predicted: {} label: {}\".format(predicted[0].item(), labels[0])))\n",
    "                log_dict={\"test accuracy\":correct/total}\n",
    "                wandb.log(log_dict)\n",
    "                \n",
    "        print('Accuracy of the network on the 10000 test images: {} %'.format(100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 96.95 %\n"
     ]
    }
   ],
   "source": [
    "test_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f2e2bce360819f88e39cac25630043f28fab3036cf9216375971b4d97393a103"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
