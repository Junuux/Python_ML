{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 여러 CNN 구조\n",
    "- Dropout\n",
    "- BatchNormalization\n",
    "- Optimization\n",
    "- Loss Function\n",
    "- Learning rate\n",
    "- Data augmentation\n",
    "- epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data를 load할 때 다양한 augmentation을 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(32, scale=(0.2, 1.0)), \n",
    "    # (0.2, 1.0) : lower and upper bounds for the random area of the crop\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomGrayscale(p=0.2),\n",
    "    # p=0.2의 확률로 gray scale로 변환\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    # 각각 R,G,B 3가지 channel에 대해 normalize\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch Size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Batch Size : 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_data = datasets.CIFAR10(\n",
    "    root=\"../data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transform, # transform.ToTensor()를 하지 않아도 됨\n",
    ")\n",
    "\n",
    "test_data = datasets.CIFAR10(\n",
    "    root=\"../data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transform,\n",
    ")\n",
    "\n",
    "# Data loader\n",
    "train_loader = DataLoader(train_data, batch_size=128, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Batch Size : 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_data = datasets.CIFAR10(\n",
    "    root=\"../data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transform,\n",
    ")\n",
    "\n",
    "test_data = datasets.CIFAR10(\n",
    "    root=\"../data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transform,\n",
    ")\n",
    "\n",
    "# Data loader\n",
    "train_loader = DataLoader(train_data, batch_size=256, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=256, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 다양한 모델 구조"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "layer 수, kernel size, stride, padding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 일반적으로 사용하는 Hyperparameter 구조"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Layer 5개, kernel size 3, stride 1, padding 1\n",
    "- Channel 3 - 32 - 64 - 128 - 256\n",
    "- 일반적인 구조로 주로 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_Model(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(CNN_Model, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.maxpool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        self.conv4 = nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.maxpool4 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        self.mlp = nn.Linear(256*2*2, num_classes)  # batch_size=256\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.maxpool1(out)\n",
    "#         print('out 1:',out.shape) # [128, 32, 16, 16]\n",
    "        \n",
    "        out = self.conv2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.maxpool2(out)\n",
    "#         print('out 2:',out.shape) # [128, 64, 8, 8]\n",
    "        \n",
    "        out = self.conv3(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.maxpool3(out)\n",
    "#         print('out 3:',out.shape) # [128, 128, 4, 4]\n",
    "        \n",
    "        out = self.conv4(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.maxpool4(out)\n",
    "#         print('out 4:',out.shape) # [128, 256, 2, 2]\n",
    "        \n",
    "        out = out.view(out.size(0), -1) # batchsize, \n",
    "        out = self.mlp(out) # 마지막 classification을 위해 필요\n",
    "        \n",
    "        return out\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = CNN_Model(num_classes=10).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Layer 3개, kernel size, stride, padding 모두 다르게\n",
    "- Channel 3 - 16 - 64 - 128\n",
    "- 원하는대로 바꿀 수 있다!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_Model(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(CNN_Model, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=7, stride=2, padding=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(16, 64, kernel_size=5, stride=2)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.maxpool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        self.mlp = nn.Linear(128*1*1, num_classes)  # 마지막에 맞게 계산해야 함  => 편하게 하려면 AdaptiveAvgPool2d(1,1) 사용\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x) \n",
    "        out = self.relu(out)\n",
    "#         print('out 1:',out.shape) # [128, 32, 14, 14]\n",
    "        \n",
    "        out = self.conv2(out) \n",
    "        out = self.relu(out)\n",
    "        out = self.maxpool2(out)\n",
    "#         print('out 2:',out.shape) # [128, 64, 2, 2]\n",
    "        \n",
    "        out = self.conv3(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.maxpool3(out)\n",
    "#         print('out 3:',out.shape) # [128, 128, 1, 1]\n",
    "        \n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.mlp(out) # 마지막 classification을 위해 필요\n",
    "        \n",
    "        return out\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = CNN_Model(num_classes=10).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ReLU\n",
    "- LeakyReLU\n",
    "- Sigmoid\n",
    "- Tanh\n",
    "등 자유롭게 사용 가능하며 일반적으로 ReLU를 많이 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_Model(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(CNN_Model, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.nonlinear = nn.ReLU()\n",
    "#         self.nonlinear = nn.LeakyReLU()\n",
    "#         self.nonlinear = nn.Sigmoid()\n",
    "#         self.nonlinear = nn.Tanh()\n",
    "        \n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.nonlinear = nn.ReLU()\n",
    "#         self.nonlinear = nn.LeakyReLU()\n",
    "#         self.nonlinear = nn.Sigmoid()\n",
    "#         self.nonlinear = nn.Tanh()\n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.nonlinear = nn.ReLU()\n",
    "#         self.nonlinear = nn.LeakyReLU()\n",
    "#         self.nonlinear = nn.Sigmoid()\n",
    "#         self.nonlinear = nn.Tanh()\n",
    "        self.maxpool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        self.conv4 = nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1)\n",
    "        self.nonlinear = nn.ReLU()\n",
    "#         self.nonlinear = nn.LeakyReLU()\n",
    "#         self.nonlinear = nn.Sigmoid()\n",
    "#         self.nonlinear = nn.Tanh()\n",
    "        self.maxpool4 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        self.mlp = nn.Linear(256*2*2, num_classes)  \n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.nonlinear(out)\n",
    "        out = self.maxpool1(out)\n",
    "#         print('out 1:',out.shape) # [128, 32, 16, 16]\n",
    "        \n",
    "        out = self.conv2(out)\n",
    "        out = self.nonlinear(out)\n",
    "        out = self.maxpool2(out)\n",
    "#         print('out 2:',out.shape) # [128, 64, 8, 8]\n",
    "        \n",
    "        out = self.conv3(out)\n",
    "        out = self.nonlinear(out)\n",
    "        out = self.maxpool3(out)\n",
    "#         print('out 3:',out.shape) # [128, 128, 4, 4]\n",
    "        \n",
    "        out = self.conv4(out)\n",
    "        out = self.nonlinear(out)\n",
    "        out = self.maxpool4(out)\n",
    "#         print('out 4:',out.shape) # [128, 256, 2, 2]\n",
    "        \n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.mlp(out) # 마지막 classification을 위해 필요\n",
    "        \n",
    "        return out\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = CNN_Model(num_classes=10).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropout / Batch Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 원하는 위치에 사용 \n",
    "- 일반적으로 Convolution Layer와 NonLinear 함수 사이에 사용한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_Model(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(CNN_Model, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.maxpool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        self.conv4 = nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.maxpool4 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        self.mlp = nn.Linear(256*2*2, num_classes)  \n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.maxpool1(out)\n",
    "#         print('out 1:',out.shape) # [128, 32, 16, 16]\n",
    "        \n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.maxpool2(out)\n",
    "#         print('out 2:',out.shape) # [128, 64, 8, 8]\n",
    "        \n",
    "        out = self.conv3(out)\n",
    "        out = self.dropout(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.maxpool3(out)\n",
    "#         print('out 3:',out.shape) # [128, 128, 4, 4]\n",
    "        \n",
    "        out = self.conv4(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.maxpool4(out)\n",
    "#         print('out 4:',out.shape) # [128, 256, 2, 2]\n",
    "        \n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.mlp(out) # 마지막 classification을 위해 필요\n",
    "        \n",
    "        return out\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = CNN_Model(num_classes=10).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "CELoss = nn.CrossEntropyLoss()\n",
    "adam_optimizer = torch.optim.Adam(model.parameters(), lr=0.001) # 최적화 알고리즘 class 선언"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of iteration : 196\n",
      "Epoch [1/3], Loss: 1.5140\n",
      "Epoch [2/3], Loss: 1.5127\n",
      "Epoch [3/3], Loss: 1.1263\n"
     ]
    }
   ],
   "source": [
    "# 뉴럴 네트워크 모델 학습\n",
    "total_epochs = 3\n",
    "print('number of iteration :', len(train_loader))\n",
    "# epoch : 모든 데이터를 한 번 학습하는 단위\n",
    "for epoch in range(total_epochs):\n",
    "    # iteration : 한 'mini-batch' 단위의 데이터를 학습하는 단위\n",
    "    for i, (images, labels) in enumerate(train_loader):  \n",
    "        # images : [mini-batch, 1, 28, 28]\n",
    "        # labels : [mini-batch]\n",
    "#         images = images.reshape(-1, 28*28).to(device) \n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        ce_loss = CELoss(outputs, labels)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        adam_optimizer.zero_grad() # 다양한 optimization 기법 적용 가능\n",
    "        ce_loss.backward() # Back propagation\n",
    "        adam_optimizer.step() # optimizer 작동\n",
    "            \n",
    "    print ('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, total_epochs, ce_loss.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 원하는 목적 및 tasks에 따라 다양한 Loss Function 적용 가능\n",
    "- 일반적으로 분류 문제는 CrossEntropyLoss, 회귀 문제에는 MSELoss를 주로 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "Loss = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "Loss = nn.L1Loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Loss = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "Loss = nn.NLLLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "Loss = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 여러 optimization을 사용할 수 있음\n",
    "- 일반적으로 SGD with momentum과 Adam을 주로 많이 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stochastic Gradient Descent\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# Stochastic Gradient Descent with momentum\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "# Adagrad\n",
    "optimizer = torch.optim.Adagrad(model.parameters(), lr=0.01)\n",
    "\n",
    "# RMSprop\n",
    "optimizer = torch.optim.RMSprop(model.parameters(), lr=0.01)\n",
    "\n",
    "# Adam\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f2e2bce360819f88e39cac25630043f28fab3036cf9216375971b4d97393a103"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
