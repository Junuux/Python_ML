{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Model, layers, optimizers, datasets\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([128, 28, 28, 1])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.random.normal(shape=(128,28,28,1), mean=0., stddev=1.) # [batch size, W, H, channel]\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### layers.Conv2d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* strides=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_after_conv1 : (128, 26, 26, 32)\n"
     ]
    }
   ],
   "source": [
    "x_after_conv1 = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(x) # filters=32 : Channel의 갯수가 32개\n",
    "print('x_after_conv1 :',x_after_conv1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* strides=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_after_conv2 : (128, 13, 13, 32)\n"
     ]
    }
   ],
   "source": [
    "x_after_conv2 = layers.Conv2D(filters=32, kernel_size=3, strides=2, activation=\"relu\")(x)\n",
    "print('x_after_conv2 :',x_after_conv2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_after_conv3 : (128, 28, 28, 32)\n"
     ]
    }
   ],
   "source": [
    "x_after_conv3 = layers.Conv2D(filters=32, kernel_size=3, strides=1, padding='same', activation=\"relu\")(x) \n",
    "# padding='same' : input과 output이 같은 크기를 갖도록 함\n",
    "print('x_after_conv3 :',x_after_conv3.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Max Pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([128, 28, 28, 1])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.random.normal(shape=(128,28,28,1), mean=0., stddev=1.) # [batch size, W, H, channel]\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_after_maxpool1: (128, 14, 14, 1)\n"
     ]
    }
   ],
   "source": [
    "x_after_maxpool1 = layers.MaxPooling2D(pool_size=(2,2), strides=(2,2))(x)\n",
    "print('x_after_maxpool1:',x_after_maxpool1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* pool_size=(4,4), padding='same'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_after_maxpool2: (128, 7, 7, 1)\n"
     ]
    }
   ],
   "source": [
    "x_after_maxpool2 = layers.MaxPooling2D(pool_size=(4,4), padding='same', strides=(4,4))(x)\n",
    "print('x_after_maxpool2:',x_after_maxpool2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average Pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([128, 28, 28, 1])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.random.normal(shape=(128,28,28,1), mean=0., stddev=1.) # [batch size, W, H, channel]\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_after_avgpool1: (128, 14, 14, 1)\n"
     ]
    }
   ],
   "source": [
    "x_after_avgpool1 = layers.AveragePooling2D(pool_size=(2,2), strides=(2,2))(x)\n",
    "print('x_after_avgpool1:',x_after_avgpool1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_after_avgpool2: (128, 4, 4, 1)\n"
     ]
    }
   ],
   "source": [
    "x_after_avgpool2 = layers.AveragePooling2D(pool_size=(7,7), strides=(7,7))(x)\n",
    "print('x_after_avgpool2:',x_after_avgpool2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global Average Pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([128, 28, 28, 1])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.random.normal(shape=(128,28,28,1), mean=0., stddev=1.) # [batch size, W, H, channel]\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* GlobalAveragePooling2D() : input값에 아무것도 없어도 1로"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_after_global_avgpool1: (128, 1)\n"
     ]
    }
   ],
   "source": [
    "x_after_global_avgpool1 = layers.GlobalAveragePooling2D()(x)\n",
    "print('x_after_global_avgpool1:',x_after_global_avgpool1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------train----------------\n",
      "images: (60000, 28, 28) 0 255\n",
      "labels: (60000,)\n",
      "normalized images: (60000, 28, 28, 1) 0.0 1.0\n",
      "----------------test----------------\n",
      "images: (10000, 28, 28) 0 255\n",
      "labels: (10000,)\n",
      "normalized images: (10000, 28, 28, 1) 0.0 1.0\n"
     ]
    }
   ],
   "source": [
    "(images_train,labels_train), (images_test,labels_test) = datasets.mnist.load_data()\n",
    "print('----------------train----------------')\n",
    "print('images:',images_train.shape, images_train.min(), images_train.max())\n",
    "print('labels:',labels_train.shape)\n",
    "images_train = images_train.reshape((60000,28,28,1)) # reshape\n",
    "images_train = images_train.astype(\"float32\")/255 # 0~1\n",
    "print('normalized images:',images_train.shape, images_train.min(), images_train.max())\n",
    "\n",
    "print('----------------test----------------')\n",
    "print('images:',images_test.shape, images_test.min(), images_test.max())\n",
    "print('labels:',labels_test.shape)\n",
    "images_test = images_test.reshape((10000,28,28,1))\n",
    "images_test = images_test.astype(\"float32\")/255\n",
    "print('normalized images:',images_test.shape, images_test.min(), images_test.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (28, 28, 1)\n",
    "num_classes = 10\n",
    "model = tf.keras.models.Sequential([\n",
    "    # kernel : (3,3)\n",
    "    tf.keras.layers.Conv2D(32, (3,3), padding='same', activation='relu', input_shape=input_shape),\n",
    "    tf.keras.layers.MaxPool2D(strides=(2,2)),\n",
    "\n",
    "    tf.keras.layers.Conv2D(64, (3,3), padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(strides=(2,2)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "375/375 [==============================] - 42s 108ms/step - loss: 0.2250 - acc: 0.9324 - val_loss: 0.0693 - val_acc: 0.9784\n",
      "Epoch 2/3\n",
      "375/375 [==============================] - 40s 106ms/step - loss: 0.0568 - acc: 0.9826 - val_loss: 0.0501 - val_acc: 0.9858\n",
      "Epoch 3/3\n",
      "375/375 [==============================] - 39s 104ms/step - loss: 0.0369 - acc: 0.9884 - val_loss: 0.0386 - val_acc: 0.9877\n"
     ]
    }
   ],
   "source": [
    "model_train = model.fit(images_train, labels_train,\n",
    "                    batch_size=128,\n",
    "                    epochs=3,\n",
    "                    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 2s - loss: 0.0321 - acc: 0.9888 - 2s/epoch - 6ms/step\n",
      "test accuracy: 0.9887999892234802\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(images_test,  labels_test, verbose=2)\n",
    "\n",
    "print('test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 모델 저장 경로"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_save_callback = tf.keras.callbacks.ModelCheckpoint(filepath=\"./cnn_model.ckpt\",\n",
    "                                                         save_weights_only=True,\n",
    "                                                         verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0288 - acc: 0.9910\n",
      "Epoch 1: saving model to .\\cnn_model.ckpt\n",
      "375/375 [==============================] - 39s 104ms/step - loss: 0.0288 - acc: 0.9910 - val_loss: 0.0366 - val_acc: 0.9883\n",
      "Epoch 2/3\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0202 - acc: 0.9937\n",
      "Epoch 2: saving model to .\\cnn_model.ckpt\n",
      "375/375 [==============================] - 41s 109ms/step - loss: 0.0202 - acc: 0.9937 - val_loss: 0.0370 - val_acc: 0.9887\n",
      "Epoch 3/3\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0166 - acc: 0.9948\n",
      "Epoch 3: saving model to .\\cnn_model.ckpt\n",
      "375/375 [==============================] - 41s 111ms/step - loss: 0.0166 - acc: 0.9948 - val_loss: 0.0361 - val_acc: 0.9898\n"
     ]
    }
   ],
   "source": [
    "model_train = model.fit(images_train, labels_train,\n",
    "                        batch_size=128,\n",
    "                        epochs=3,\n",
    "                        validation_split=0.2,\n",
    "                        callbacks=[model_save_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x1e2ab2447c0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_path=\"./cnn_model.ckpt\"\n",
    "model.load_weights(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 5s - loss: 0.0260 - acc: 0.9904 - 5s/epoch - 15ms/step\n",
      "accuracy: 99.04%\n"
     ]
    }
   ],
   "source": [
    "loss,acc = model.evaluate(images_test,  labels_test, verbose=2)\n",
    "print(\"accuracy: {:5.2f}%\".format(100*acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f2e2bce360819f88e39cac25630043f28fab3036cf9216375971b4d97393a103"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
