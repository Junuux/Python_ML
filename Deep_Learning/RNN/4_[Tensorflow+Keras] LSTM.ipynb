{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Model, layers, optimizers, datasets\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.random.normal(shape=(32,784,100), mean=0., stddev=1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = layers.LSTM(units=10) \n",
    "# units : output의 dimension (hidden dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: (32, 784, 100)\n",
      "----------------------------------------\n",
      "output: (32, 10)\n"
     ]
    }
   ],
   "source": [
    "print('x:',x.shape)\n",
    "output = lstm(x)\n",
    "print('-'*40)\n",
    "print('output:',output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm2 = layers.LSTM(units=10, return_sequences=True, return_state=True)\n",
    "# return_sequences : output sequence의 마지막 output을 return할 지(False) full sequence를 return할 지(True)\n",
    "# return_state : output외에 last state(hidden, cell)도 return할 지 여부"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: (32, 784, 100)\n",
      "output2: (32, 784, 10)\n",
      "final_hidden_state: (32, 10)\n",
      "final_cell_state: (32, 10)\n"
     ]
    }
   ],
   "source": [
    "print('x:',x.shape)\n",
    "output2, final_hidden_state, final_cell_state = lstm2(x)\n",
    "print('output2:',output2.shape)\n",
    "print('final_hidden_state:',final_hidden_state.shape)\n",
    "print('final_cell_state:',final_cell_state.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(Model):\n",
    "    def __init__(self, units1, units2, num_classes):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.sequential = tf.keras.Sequential([\n",
    "            layers.LSTM(units1, return_sequences=True),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.LSTM(units2),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Dense(num_classes, activation=tf.nn.softmax)\n",
    "        ])\n",
    "    \n",
    "    def call(self, x):\n",
    "        x = self.sequential(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = datasets.mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "units_1 = 128\n",
    "units_2 = 256\n",
    "num_classes = 10\n",
    "\n",
    "model = LSTM(units_1, units_2, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"sgd\",\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=[\"accuracy\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "469/469 [==============================] - 80s 164ms/step - loss: 0.6319 - accuracy: 0.8015 - val_loss: 0.8875 - val_accuracy: 0.7069\n",
      "Epoch 2/3\n",
      "469/469 [==============================] - 79s 169ms/step - loss: 0.3007 - accuracy: 0.9073 - val_loss: 0.4086 - val_accuracy: 0.8672\n",
      "Epoch 3/3\n",
      "469/469 [==============================] - 79s 168ms/step - loss: 0.2101 - accuracy: 0.9352 - val_loss: 0.1812 - val_accuracy: 0.9443\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x25b0fc07310>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    x_train, y_train, validation_data=(x_test, y_test), batch_size=128, epochs=3\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bidirectional LSTM Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bi_LSTM(Model):\n",
    "    def __init__(self, units1, units2, num_classes):\n",
    "        super(Bi_LSTM, self).__init__()\n",
    "        self.sequential = tf.keras.Sequential([\n",
    "            layers.Bidirectional(\n",
    "                layers.LSTM(units1, return_sequences=True)),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Bidirectional(layers.LSTM(units2)),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Dense(num_classes, activation=tf.nn.softmax)\n",
    "        ])\n",
    "    \n",
    "    def call(self, x):\n",
    "        # x = self.sequential(x)\n",
    "        x = self.sequential(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = datasets.mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "units_1 = 128\n",
    "units_2 = 256\n",
    "num_classes = 10\n",
    "\n",
    "model = Bi_LSTM(units_1, units_2, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"sgd\",\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=[\"accuracy\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "469/469 [==============================] - 207s 428ms/step - loss: 0.4456 - accuracy: 0.8713 - val_loss: 0.7286 - val_accuracy: 0.7846\n",
      "Epoch 2/3\n",
      "469/469 [==============================] - 203s 434ms/step - loss: 0.2063 - accuracy: 0.9406 - val_loss: 0.1661 - val_accuracy: 0.9495\n",
      "Epoch 3/3\n",
      "469/469 [==============================] - 201s 428ms/step - loss: 0.1488 - accuracy: 0.9563 - val_loss: 0.1369 - val_accuracy: 0.9581\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x25b1555e040>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    x_train, y_train, validation_data=(x_test, y_test), batch_size=128, epochs=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
